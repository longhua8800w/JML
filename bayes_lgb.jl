
# æ–‡ä»¶åï¼šmlj_workflow_with_core_api.jl
# ç­–ç•¥ï¼šç”¨MLJç®¡ç†æ•°æ®ï¼Œç”¨åº“çš„æ ¸å¿ƒAPIè®­ç»ƒï¼Œå†ç”¨MLJè¯„ä¼°
using Serialization,CategoricalArrays,DataFrames,Dates
obj = deserialize("data/xy")

y = obj.y
X = obj.X


# =====================================================
# LightGBM ç«¯åˆ°ç«¯ AUC ä¼˜åŒ–å·¥ä½œæµ
# =====================================================
using MLJ, MLJTuning
using LightGBM, Random, Statistics
using ROCAnalysis  # ç”¨äºè®¡ç®—AUC

Random.seed!(42)

# è½¬æ¢ä¸º MLJ éœ€è¦çš„æ ¼å¼
y_cat = coerce(y, Multiclass)  # å¿…é¡»è½¬æ¢ä¸º Multiclass ç±»å‹
#coerce!(X, autotype(X, :few_to_finite))

# æ•°æ®åˆ†å‰²ï¼š60%è®­ç»ƒï¼Œ20%éªŒè¯ï¼ˆè°ƒä¼˜ï¼‰ï¼Œ20%æµ‹è¯•
train_idx, temp_idx = partition(eachindex(y_cat), 0.6, shuffle=true, rng=42)
val_idx, test_idx = partition(temp_idx, 0.5, shuffle=true, rng=42)

X_train = X[train_idx, :]; y_train = y_cat[train_idx]
X_val = X[val_idx, :];   y_val = y_cat[val_idx]
X_test = X[test_idx, :]; y_test = y_cat[test_idx]


# 2. AUC è¯„ä¼°å‡½æ•°

using MLJBase
function calculate_auc(mach, X_data, y_true)
    y_prob = MLJ.predict(mach, X_data)
    res = MLJ.auc(y_prob, y_true)
    return res
end


# åŠ è½½ LightGBM åˆ†ç±»å™¨
LGB = @load LGBMClassifier pkg=LightGBM

# åŸºç¡€æ¨¡å‹é…ç½® - é’ˆå¯¹ AUC ä¼˜åŒ–
base_model = LGB(
    objective="binary",
    metric=["auc"],           # ä½¿ç”¨ AUC ä½œä¸ºè¯„ä¼°æŒ‡æ ‡
    boosting="gbdt",
    verbosity=-1,           # å‡å°‘è¾“å‡º
    seed=42,
    is_unbalance=true       # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
)



# 4. å®šä¹‰è°ƒä¼˜å‚æ•°ç©ºé—´ï¼ˆAUCä¼˜åŒ–ä¸“ç”¨ï¼‰

tuning_ranges = [
    # æ ¸å¿ƒå¤æ‚åº¦å‚æ•°
    range(base_model, :num_leaves, lower=20, upper=150, scale=:log),  # å¶å­æ•°é‡
    range(base_model, :max_depth, lower=3, upper=12),                 # æ ‘çš„æœ€å¤§æ·±åº¦
    
    # å­¦ä¹ è¿‡ç¨‹å‚æ•°
    range(base_model, :learning_rate, lower=0.01, upper=0.3, scale=:log),
    range(base_model, :num_iterations, lower=50, upper=500, scale=:log),
    
    # æ­£åˆ™åŒ–å‚æ•°ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæå‡AUCï¼‰
    range(base_model, :lambda_l1, lower=0.0, upper=10.0, scale=:log),  # L1æ­£åˆ™åŒ–
    range(base_model, :lambda_l2, lower=0.0, upper=10.0, scale=:log),  # L2æ­£åˆ™åŒ–
    range(base_model, :min_data_in_leaf, lower=10, upper=100, scale=:log),
    
    # éšæœºåŒ–å‚æ•°ï¼ˆæå‡æ¨¡å‹é²æ£’æ€§ï¼‰
    range(base_model, :feature_fraction, lower=0.6, upper=1.0),  # ç‰¹å¾é‡‡æ ·æ¯”ä¾‹
    range(base_model, :bagging_fraction, lower=0.6, upper=1.0),  # æ•°æ®é‡‡æ ·æ¯”ä¾‹
    range(base_model, :bagging_freq, lower=1, upper=10)          # baggingé¢‘ç‡
]

println("   è°ƒä¼˜å‚æ•° (9ä¸ªå…³é”®å‚æ•°):")
for (i, r) in enumerate(tuning_ranges)
    scale_info = r.scale == :log ? "[å¯¹æ•°å°ºåº¦]" : ""
    println("   $(lpad(i,2)). $(rpad(string(r.field), 20)): $(r.lower) â†’ $(r.upper) $scale_info")
end

# 5. é…ç½®é‡å¤CVè°ƒä¼˜ç­–ç•¥
println("\n5. ğŸ”„ é…ç½®é‡å¤CVè°ƒä¼˜ç­–ç•¥")

# ä½¿ç”¨5æŠ˜äº¤å‰éªŒè¯ï¼Œé…åˆéšæœºæœç´¢
cv = CV(nfolds=5, shuffle=true, rng=123)

# æŸ¥çœ‹ MLJ å®˜æ–¹æ”¯æŒçš„ä¼˜åŒ–ç­–ç•¥
using MLJTuning, MLJBalancing

println("MLJ å®˜æ–¹æ”¯æŒçš„è°ƒä¼˜ç­–ç•¥:")
strategies = MLJTuning.TuningStrategy()
for s in strategies
    println("  - $s")
end